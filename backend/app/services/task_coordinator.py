"""
CWatcher çµ±ä¸€ä»»å‹™å”èª¿å™¨

çµ±ç±Œæ‰€æœ‰å®šæ™‚ä»»å‹™çš„åŸ·è¡Œï¼Œç¢ºä¿ä»»å‹™é–“çš„å”èª¿æ€§å’Œé¿å…è³‡æºè¡çª
è² è²¬å„ªåŒ–ä»»å‹™åŸ·è¡Œé †åºã€è³‡æºç®¡ç†å’Œç³»çµ±æ•´é«”æ•ˆèƒ½
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from enum import Enum
from collections import defaultdict

from services.task_scheduler import task_scheduler, TaskType, TaskStatus
from services.ssh_manager import ssh_manager
from services.websocket_push_service import push_service
from services.data_processor import data_processor
from core.config import settings

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


class CoordinatorMode(Enum):
    """å”èª¿å™¨æ¨¡å¼"""
    NORMAL = "normal"          # æ­£å¸¸æ¨¡å¼
    HIGH_LOAD = "high_load"    # é«˜è² è¼‰æ¨¡å¼
    MAINTENANCE = "maintenance" # ç¶­è­·æ¨¡å¼
    EMERGENCY = "emergency"    # ç·Šæ€¥æ¨¡å¼


class ResourceType(Enum):
    """è³‡æºé¡å‹"""
    SSH_CONNECTION = "ssh_connection"
    DATABASE = "database"
    WEBSOCKET = "websocket"
    CPU = "cpu"
    MEMORY = "memory"
    DISK_IO = "disk_io"


@dataclass
class ResourceLock:
    """è³‡æºé–å®šè¨˜éŒ„"""
    resource_type: ResourceType
    resource_id: str
    locked_by: str  # ä»»å‹™ID
    lock_time: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    timeout: float = 300.0  # è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
    
    def is_expired(self) -> bool:
        """æª¢æŸ¥é–æ˜¯å¦éæœŸ"""
        current_time = datetime.now(timezone.utc)
        if self.lock_time.tzinfo is None:
            # å¦‚æœ lock_time æ˜¯ naive datetimeï¼Œè½‰æ›ç‚º UTC
            lock_time_utc = self.lock_time.replace(tzinfo=timezone.utc)
        else:
            lock_time_utc = self.lock_time
        return (current_time - lock_time_utc).total_seconds() > self.timeout


@dataclass
class TaskDependency:
    """ä»»å‹™ä¾è³´é—œä¿‚"""
    task_id: str
    depends_on: Set[str]  # ä¾è³´çš„ä»»å‹™IDé›†åˆ
    conflicts_with: Set[str]  # è¡çªçš„ä»»å‹™IDé›†åˆ
    required_resources: Set[ResourceType]
    priority: int = 0  # å„ªå…ˆç´šï¼ˆæ•¸å­—è¶Šå¤§å„ªå…ˆç´šè¶Šé«˜ï¼‰


@dataclass
class CoordinatorStats:
    """å”èª¿å™¨çµ±è¨ˆ"""
    total_coordinated_tasks: int = 0
    resource_conflicts_resolved: int = 0
    dependency_delays: int = 0
    optimization_savings_seconds: float = 0.0
    mode_switches: Dict[CoordinatorMode, int] = field(default_factory=lambda: defaultdict(int))
    last_optimization_time: Optional[datetime] = None


class TaskCoordinator:
    """çµ±ä¸€ä»»å‹™å”èª¿å™¨"""
    
    def __init__(self):
        self.mode = CoordinatorMode.NORMAL
        self.resource_locks: Dict[str, ResourceLock] = {}
        self.task_dependencies: Dict[str, TaskDependency] = {}
        self.execution_queue: List[str] = []
        self.stats = CoordinatorStats()
        self.is_running = False
        self._coordinator_task: Optional[asyncio.Task] = None
        
        # ç³»çµ±è² è¼‰ç›£æ§
        self.system_load = {
            "cpu_usage": 0.0,
            "memory_usage": 0.0,
            "active_connections": 0,
            "pending_tasks": 0
        }
        
        # åˆå§‹åŒ–ä»»å‹™ä¾è³´é—œä¿‚
        self._setup_task_dependencies()
    
    def _setup_task_dependencies(self):
        """è¨­ç½®ä»»å‹™ä¾è³´é—œä¿‚"""
        
        # ç›£æ§æ•¸æ“šæ”¶é›†ä»»å‹™
        self.task_dependencies["monitoring_collection"] = TaskDependency(
            task_id="monitoring_collection",
            depends_on=set(),  # ç¨ç«‹ä»»å‹™
            conflicts_with={"system_info_update"},  # é¿å…èˆ‡ç³»çµ±è³‡è¨Šæ›´æ–°è¡çª
            required_resources={ResourceType.SSH_CONNECTION, ResourceType.DATABASE},
            priority=10  # æœ€é«˜å„ªå…ˆç´š
        )
        
        # WebSocket æ¨é€ä»»å‹™
        self.task_dependencies["websocket_push"] = TaskDependency(
            task_id="websocket_push",
            depends_on={"monitoring_collection"},  # ä¾è³´ç›£æ§æ•¸æ“šæ”¶é›†
            conflicts_with=set(),
            required_resources={ResourceType.WEBSOCKET, ResourceType.DATABASE},
            priority=9
        )
        
        # ç³»çµ±è³‡è¨Šæ›´æ–°ä»»å‹™
        self.task_dependencies["system_info_update"] = TaskDependency(
            task_id="system_info_update",
            depends_on=set(),
            conflicts_with={"monitoring_collection"},  # é¿å…SSHè³‡æºè¡çª
            required_resources={ResourceType.SSH_CONNECTION, ResourceType.DATABASE},
            priority=5
        )
        
        # ç·©è¡å€åˆ·æ–°ä»»å‹™
        self.task_dependencies["buffer_flush"] = TaskDependency(
            task_id="buffer_flush",
            depends_on=set(),
            conflicts_with={"daily_data_cleanup", "weekly_archive_cleanup"},
            required_resources={ResourceType.DATABASE, ResourceType.DISK_IO},
            priority=6
        )
        
        # ç³»çµ±å¥åº·æª¢æŸ¥
        self.task_dependencies["system_health_check"] = TaskDependency(
            task_id="system_health_check",
            depends_on=set(),
            conflicts_with=set(),
            required_resources={ResourceType.SSH_CONNECTION, ResourceType.DATABASE},
            priority=7
        )
        
        # æ•¸æ“šæ¸…ç†ä»»å‹™
        self.task_dependencies["daily_data_cleanup"] = TaskDependency(
            task_id="daily_data_cleanup",
            depends_on=set(),
            conflicts_with={"buffer_flush", "weekly_archive_cleanup"},
            required_resources={ResourceType.DATABASE, ResourceType.DISK_IO},
            priority=3
        )
        
        # æ­¸æª”æ¸…ç†ä»»å‹™
        self.task_dependencies["weekly_archive_cleanup"] = TaskDependency(
            task_id="weekly_archive_cleanup",
            depends_on={"daily_data_cleanup"},
            conflicts_with={"buffer_flush"},
            required_resources={ResourceType.DISK_IO},
            priority=2
        )
        
        # å„²å­˜ç›£æ§ä»»å‹™
        self.task_dependencies["storage_monitor"] = TaskDependency(
            task_id="storage_monitor",
            depends_on=set(),
            conflicts_with=set(),
            required_resources={ResourceType.DISK_IO},
            priority=4
        )
    
    async def start(self):
        """å•Ÿå‹•ä»»å‹™å”èª¿å™¨"""
        if self.is_running:
            logger.warning("ä»»å‹™å”èª¿å™¨å·²åœ¨é‹è¡Œä¸­")
            return
        
        self.is_running = True
        logger.info("ä»»å‹™å”èª¿å™¨å•Ÿå‹•ä¸­...")
        
        # å•Ÿå‹•å”èª¿å™¨ä¸»å¾ªç’°
        self._coordinator_task = asyncio.create_task(self._coordinator_loop())
        
        logger.info("ä»»å‹™å”èª¿å™¨å·²å•Ÿå‹•")
    
    async def stop(self):
        """åœæ­¢ä»»å‹™å”èª¿å™¨"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        if self._coordinator_task and not self._coordinator_task.done():
            self._coordinator_task.cancel()
            try:
                await self._coordinator_task
            except asyncio.CancelledError:
                pass
        
        # æ¸…ç†è³‡æºé–
        self.resource_locks.clear()
        
        logger.info("ä»»å‹™å”èª¿å™¨å·²åœæ­¢")
    
    async def _coordinator_loop(self):
        """å”èª¿å™¨ä¸»å¾ªç’°"""
        while self.is_running:
            try:
                # æ›´æ–°ç³»çµ±è² è¼‰
                await self._update_system_load()
                
                # èª¿æ•´å”èª¿å™¨æ¨¡å¼
                await self._adjust_coordinator_mode()
                
                # æ¸…ç†éæœŸçš„è³‡æºé–
                self._cleanup_expired_locks()
                
                # å„ªåŒ–ä»»å‹™åŸ·è¡Œ
                await self._optimize_task_execution()
                
                # æ¯30ç§’åŸ·è¡Œä¸€æ¬¡å”èª¿æª¢æŸ¥
                await asyncio.sleep(30)
                
            except Exception as e:
                logger.error(f"å”èª¿å™¨å¾ªç’°ç™¼ç”ŸéŒ¯èª¤: {e}")
                await asyncio.sleep(5)
    
    async def _update_system_load(self):
        """æ›´æ–°ç³»çµ±è² è¼‰æŒ‡æ¨™"""
        try:
            # ç²å–è™•ç†çµ±è¨ˆ
            processing_stats = data_processor.get_processing_stats()
            
            # ç²å–é€£æ¥çµ±è¨ˆ
            active_connections = push_service.get_connection_count()
            
            # ç²å–ä»»å‹™çµ±è¨ˆ
            scheduler_status = task_scheduler.get_task_health_summary()
            
            self.system_load.update({
                "memory_usage": processing_stats.buffer_size / 1000,  # ç°¡åŒ–çš„è¨˜æ†¶é«”ä½¿ç”¨ç‡
                "active_connections": active_connections,
                "pending_tasks": len([t for t in task_scheduler.tasks.values() if t.enabled])
            })
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç³»çµ±è² è¼‰å¤±æ•—: {e}")
    
    async def _adjust_coordinator_mode(self):
        """æ ¹æ“šç³»çµ±è² è¼‰èª¿æ•´å”èª¿å™¨æ¨¡å¼"""
        current_mode = self.mode
        
        # æª¢æŸ¥ç³»çµ±è² è¼‰æŒ‡æ¨™
        high_load_indicators = 0
        
        if self.system_load["memory_usage"] > 80:
            high_load_indicators += 1
        
        if self.system_load["active_connections"] > 50:
            high_load_indicators += 1
        
        if self.system_load["pending_tasks"] > 10:
            high_load_indicators += 1
        
        # æª¢æŸ¥å¤±æ•—ä»»å‹™
        failed_tasks = task_scheduler.get_failed_tasks()
        critical_failures = [t for t in failed_tasks if t["consecutive_failures"] >= 3]
        
        # æ±ºå®šæ¨¡å¼
        if critical_failures:
            new_mode = CoordinatorMode.EMERGENCY
        elif high_load_indicators >= 2:
            new_mode = CoordinatorMode.HIGH_LOAD
        else:
            new_mode = CoordinatorMode.NORMAL
        
        # åˆ‡æ›æ¨¡å¼
        if new_mode != current_mode:
            self.mode = new_mode
            self.stats.mode_switches[new_mode] += 1
            logger.info(f"å”èª¿å™¨æ¨¡å¼åˆ‡æ›: {current_mode.value} -> {new_mode.value}")
            
            # æ ¹æ“šæ–°æ¨¡å¼èª¿æ•´ç­–ç•¥
            await self._apply_mode_strategy()
    
    async def _apply_mode_strategy(self):
        """æ‡‰ç”¨æ¨¡å¼ç­–ç•¥"""
        if self.mode == CoordinatorMode.HIGH_LOAD:
            # é«˜è² è¼‰æ¨¡å¼ï¼šå»¶é•·ä»»å‹™é–“éš”ï¼Œæ¸›å°‘ä¸¦ç™¼
            logger.info("æ‡‰ç”¨é«˜è² è¼‰ç­–ç•¥ï¼šé™ä½ä»»å‹™é »ç‡")
            
        elif self.mode == CoordinatorMode.EMERGENCY:
            # ç·Šæ€¥æ¨¡å¼ï¼šåƒ…åŸ·è¡Œé—œéµä»»å‹™
            logger.warning("æ‡‰ç”¨ç·Šæ€¥ç­–ç•¥ï¼šåƒ…åŸ·è¡Œæ ¸å¿ƒç›£æ§ä»»å‹™")
            
            # æš«æ™‚åœç”¨éé—œéµä»»å‹™
            non_critical_tasks = ["storage_monitor", "daily_data_cleanup", "weekly_archive_cleanup"]
            for task_id in non_critical_tasks:
                if task_id in task_scheduler.tasks:
                    await task_scheduler.disable_task(task_id)
        
        elif self.mode == CoordinatorMode.NORMAL:
            # æ­£å¸¸æ¨¡å¼ï¼šç¢ºä¿æ‰€æœ‰ä»»å‹™éƒ½å•Ÿç”¨
            logger.info("æ¢å¾©æ­£å¸¸æ¨¡å¼ï¼šé‡æ–°å•Ÿç”¨æ‰€æœ‰ä»»å‹™")
            
            for task_id in task_scheduler.tasks:
                task = task_scheduler.tasks[task_id]
                if not task.enabled and task.consecutive_failures < task.auto_disable_threshold:
                    await task_scheduler.enable_task(task_id)
    
    def _cleanup_expired_locks(self):
        """æ¸…ç†éæœŸçš„è³‡æºé–"""
        expired_locks = []
        for lock_key, lock in self.resource_locks.items():
            if lock.is_expired():
                expired_locks.append(lock_key)
        
        for lock_key in expired_locks:
            del self.resource_locks[lock_key]
            logger.debug(f"æ¸…ç†éæœŸè³‡æºé–: {lock_key}")
    
    async def _optimize_task_execution(self):
        """å„ªåŒ–ä»»å‹™åŸ·è¡Œ"""
        if self.mode == CoordinatorMode.EMERGENCY:
            return  # ç·Šæ€¥æ¨¡å¼ä¸é€²è¡Œå„ªåŒ–
        
        start_time = time.time()
        
        # æª¢æŸ¥å³å°‡åŸ·è¡Œçš„ä»»å‹™
        upcoming_tasks = self._get_upcoming_tasks()
        
        if not upcoming_tasks:
            return
        
        # æ ¹æ“šä¾è³´é—œä¿‚å’Œè¡çªå„ªåŒ–åŸ·è¡Œé †åº
        optimized_order = self._calculate_optimal_execution_order(upcoming_tasks)
        
        # æ‡‰ç”¨å„ªåŒ–
        conflicts_resolved = await self._apply_execution_optimization(optimized_order)
        
        optimization_time = time.time() - start_time
        
        if conflicts_resolved > 0:
            self.stats.resource_conflicts_resolved += conflicts_resolved
            self.stats.optimization_savings_seconds += optimization_time
            self.stats.last_optimization_time = datetime.now(timezone.utc)
            
            logger.info(f"ä»»å‹™åŸ·è¡Œå„ªåŒ–å®Œæˆï¼šè§£æ±º {conflicts_resolved} å€‹è¡çªï¼Œè€—æ™‚ {optimization_time:.2f}s")
    
    def _get_upcoming_tasks(self) -> List[str]:
        """ç²å–å³å°‡åŸ·è¡Œçš„ä»»å‹™åˆ—è¡¨"""
        upcoming_tasks = []
        current_time = datetime.now(timezone.utc)
        
        for task_id, task in task_scheduler.tasks.items():
            if task.enabled and task.next_run:
                # æª¢æŸ¥æ˜¯å¦åœ¨æœªä¾†5åˆ†é˜å…§åŸ·è¡Œ
                time_until_run = (task.next_run - current_time).total_seconds()
                if 0 <= time_until_run <= 300:  # 5åˆ†é˜å…§
                    upcoming_tasks.append(task_id)
        
        return upcoming_tasks
    
    def _calculate_optimal_execution_order(self, task_ids: List[str]) -> List[str]:
        """è¨ˆç®—æœ€ä½³åŸ·è¡Œé †åº"""
        # æ ¹æ“šå„ªå…ˆç´šå’Œä¾è³´é—œä¿‚æ’åº
        task_priorities = []
        
        for task_id in task_ids:
            dependency = self.task_dependencies.get(task_id)
            if dependency:
                priority = dependency.priority
                # æª¢æŸ¥ä¾è³´æ˜¯å¦æ»¿è¶³
                dependencies_met = all(
                    dep_id not in task_ids or self._is_dependency_satisfied(dep_id)
                    for dep_id in dependency.depends_on
                )
                
                if not dependencies_met:
                    priority -= 5  # é™ä½å„ªå…ˆç´š
                
                task_priorities.append((task_id, priority))
            else:
                task_priorities.append((task_id, 0))
        
        # æŒ‰å„ªå…ˆç´šæ’åºï¼ˆé«˜å„ªå…ˆç´šåœ¨å‰ï¼‰
        task_priorities.sort(key=lambda x: x[1], reverse=True)
        
        return [task_id for task_id, _ in task_priorities]
    
    def _is_dependency_satisfied(self, task_id: str) -> bool:
        """æª¢æŸ¥ä»»å‹™ä¾è³´æ˜¯å¦æ»¿è¶³"""
        if task_id not in task_scheduler.tasks:
            return False
        
        task = task_scheduler.tasks[task_id]
        
        # æª¢æŸ¥ä»»å‹™æœ€è¿‘æ˜¯å¦æˆåŠŸåŸ·è¡Œ
        if task.last_run and task.consecutive_failures == 0:
            # ç¢ºä¿æ™‚é–“æ¯”è¼ƒä¸€è‡´æ€§
            current_time = datetime.now(timezone.utc) if hasattr(task.last_run, 'tzinfo') and task.last_run.tzinfo else datetime.now()
            
            # å¦‚æœ task.last_run æ²’æœ‰æ™‚å€ä¿¡æ¯ï¼Œå‡è¨­ç‚ºç•¶å‰ç³»çµ±æ™‚å€
            if hasattr(task.last_run, 'tzinfo') and task.last_run.tzinfo is None:
                task_last_run = task.last_run
            else:
                task_last_run = task.last_run
                
            time_since_run = (current_time - task_last_run).total_seconds()
            return time_since_run < 3600  # 1å°æ™‚å…§æˆåŠŸåŸ·è¡Œé
        
        return False
    
    async def _apply_execution_optimization(self, optimized_order: List[str]) -> int:
        """æ‡‰ç”¨åŸ·è¡Œå„ªåŒ–"""
        conflicts_resolved = 0
        
        for i, task_id in enumerate(optimized_order):
            dependency = self.task_dependencies.get(task_id)
            if not dependency:
                continue
            
            # æª¢æŸ¥è³‡æºè¡çª
            for conflicting_task_id in dependency.conflicts_with:
                if conflicting_task_id in optimized_order:
                    conflicting_index = optimized_order.index(conflicting_task_id)
                    
                    # å¦‚æœè¡çªä»»å‹™åœ¨ç•¶å‰ä»»å‹™ä¹‹å‰ï¼Œèª¿æ•´æ™‚é–“
                    if conflicting_index < i:
                        await self._delay_task_execution(task_id, 60)  # å»¶é²1åˆ†é˜
                        conflicts_resolved += 1
                        logger.info(f"è§£æ±ºä»»å‹™è¡çªï¼š{task_id} å»¶é²åŸ·è¡Œä»¥é¿å…èˆ‡ {conflicting_task_id} è¡çª")
        
        return conflicts_resolved
    
    async def _delay_task_execution(self, task_id: str, delay_seconds: int):
        """å»¶é²ä»»å‹™åŸ·è¡Œ"""
        if task_id not in task_scheduler.tasks:
            return
        
        task = task_scheduler.tasks[task_id]
        if task.next_run:
            new_run_time = task.next_run + timedelta(seconds=delay_seconds)
            
            # é‡æ–°å®‰æ’ä»»å‹™
            job = task_scheduler.scheduler.get_job(task_id)
            if job:
                job.modify(next_run_time=new_run_time)
                task.next_run = new_run_time
                self.stats.dependency_delays += 1
    
    def get_coordination_status(self) -> Dict[str, Any]:
        """ç²å–å”èª¿å™¨ç‹€æ…‹"""
        return {
            "mode": self.mode.value,
            "is_running": self.is_running,
            "system_load": self.system_load.copy(),
            "active_resource_locks": len(self.resource_locks),
            "task_dependencies": len(self.task_dependencies),
            "stats": {
                "total_coordinated_tasks": self.stats.total_coordinated_tasks,
                "resource_conflicts_resolved": self.stats.resource_conflicts_resolved,
                "dependency_delays": self.stats.dependency_delays,
                "optimization_savings_seconds": self.stats.optimization_savings_seconds,
                "mode_switches": dict(self.stats.mode_switches),
                "last_optimization_time": self.stats.last_optimization_time.isoformat() if self.stats.last_optimization_time else None
            }
        }
    
    def get_resource_usage(self) -> Dict[str, Any]:
        """ç²å–è³‡æºä½¿ç”¨æƒ…æ³"""
        resource_usage = defaultdict(list)
        
        for lock_key, lock in self.resource_locks.items():
            resource_usage[lock.resource_type.value].append({
                "resource_id": lock.resource_id,
                "locked_by": lock.locked_by,
                "lock_time": lock.lock_time.isoformat(),
                "timeout": lock.timeout
            })
        
        return dict(resource_usage)


# å…¨åŸŸä»»å‹™å”èª¿å™¨å¯¦ä¾‹
task_coordinator = TaskCoordinator()


# ä¾¿åˆ©å‡½æ•¸
async def start_task_coordinator():
    """å•Ÿå‹•ä»»å‹™å”èª¿å™¨"""
    await task_coordinator.start()


async def stop_task_coordinator():
    """åœæ­¢ä»»å‹™å”èª¿å™¨"""
    await task_coordinator.stop()


def get_coordination_status():
    """ç²å–å”èª¿å™¨ç‹€æ…‹"""
    return task_coordinator.get_coordination_status()


if __name__ == "__main__":
    # æ¸¬è©¦ä»»å‹™å”èª¿å™¨
    
    async def test_coordinator():
        """æ¸¬è©¦å”èª¿å™¨"""
        print("ğŸ¯ æ¸¬è©¦ä»»å‹™å”èª¿å™¨...")
        
        try:
            # å•Ÿå‹•å”èª¿å™¨
            await task_coordinator.start()
            print("âœ… å”èª¿å™¨å•Ÿå‹•æˆåŠŸ")
            
            # é‹è¡Œä¸€æ®µæ™‚é–“
            await asyncio.sleep(60)
            
            # ç²å–ç‹€æ…‹
            status = task_coordinator.get_coordination_status()
            print(f"ğŸ“Š å”èª¿å™¨ç‹€æ…‹: {status}")
            
            # åœæ­¢å”èª¿å™¨
            await task_coordinator.stop()
            print("âœ… å”èª¿å™¨å·²åœæ­¢")
            
        except Exception as e:
            print(f"âŒ å”èª¿å™¨æ¸¬è©¦å¤±æ•—: {e}")
    
    # åŸ·è¡Œæ¸¬è©¦
    asyncio.run(test_coordinator())