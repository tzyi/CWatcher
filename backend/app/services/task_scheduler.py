"""
CWatcher ä»»å‹™èª¿åº¦æœå‹™

å°ˆé–€è² è²¬å®šæ™‚ä»»å‹™çš„æ’ç¨‹å’ŒåŸ·è¡Œ
åŒ…æ‹¬æ•¸æ“šæ¸…ç†ã€ç³»çµ±ç›£æ§ã€å¥åº·æª¢æŸ¥ç­‰èƒŒæ™¯ä»»å‹™
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
import signal
import sys

from app.core.config import settings
from app.services.data_cleaner import data_cleaner, CleanupLevel
from app.services.data_processor import data_processor
from app.services.monitoring_collector import monitoring_service
from app.services.websocket_push_service import push_service
from app.services.system_collector import system_collector
from app.services.ssh_manager import ssh_manager
from app.db.base import get_db
from app.models.server import Server

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


class TaskType(Enum):
    """ä»»å‹™é¡å‹"""
    # æ ¸å¿ƒç›£æ§ä»»å‹™
    MONITORING_COLLECTION = "monitoring_collection"
    WEBSOCKET_PUSH = "websocket_push"
    SYSTEM_INFO_UPDATE = "system_info_update"
    
    # ç¶­è­·ä»»å‹™
    DATA_CLEANUP = "data_cleanup"
    ARCHIVE_CLEANUP = "archive_cleanup"
    HEALTH_CHECK = "health_check"
    BUFFER_FLUSH = "buffer_flush"
    STORAGE_MONITOR = "storage_monitor"


class TaskStatus(Enum):
    """ä»»å‹™ç‹€æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    DISABLED = "disabled"


@dataclass
class TaskExecutionResult:
    """ä»»å‹™åŸ·è¡Œçµæœ"""
    task_id: str
    task_type: TaskType
    status: TaskStatus
    start_time: datetime
    end_time: Optional[datetime] = None
    duration: float = 0.0
    result_data: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "task_type": self.task_type.value,
            "status": self.status.value,
            "start_time": self.start_time.isoformat(),
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "duration": self.duration,
            "result_data": self.result_data,
            "error_message": self.error_message
        }


@dataclass
class ScheduledTask:
    """æ’ç¨‹ä»»å‹™å®šç¾©"""
    task_id: str
    task_type: TaskType
    name: str
    description: str
    trigger: str  # cron expression or interval
    function: Callable
    enabled: bool = True
    last_run: Optional[datetime] = None
    next_run: Optional[datetime] = None
    run_count: int = 0
    failure_count: int = 0
    consecutive_failures: int = 0  # é€£çºŒå¤±æ•—æ¬¡æ•¸
    max_retries: int = 3  # æœ€å¤§é‡è©¦æ¬¡æ•¸
    retry_delay: float = 60.0  # é‡è©¦å»¶é²ï¼ˆç§’ï¼‰
    auto_disable_threshold: int = 5  # è‡ªå‹•åœç”¨é–¾å€¼ï¼ˆé€£çºŒå¤±æ•—æ¬¡æ•¸ï¼‰
    last_failure_time: Optional[datetime] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "task_type": self.task_type.value,
            "name": self.name,
            "description": self.description,
            "trigger": self.trigger,
            "enabled": self.enabled,
            "last_run": self.last_run.isoformat() if self.last_run else None,
            "next_run": self.next_run.isoformat() if self.next_run else None,
            "run_count": self.run_count,
            "failure_count": self.failure_count,
            "consecutive_failures": self.consecutive_failures,
            "max_retries": self.max_retries,
            "retry_delay": self.retry_delay,
            "auto_disable_threshold": self.auto_disable_threshold,
            "last_failure_time": self.last_failure_time.isoformat() if self.last_failure_time else None
        }


class TaskScheduler:
    """ä»»å‹™èª¿åº¦å™¨"""
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.tasks: Dict[str, ScheduledTask] = {}
        self.execution_history: List[TaskExecutionResult] = []
        self.max_history_size = 1000
        self.is_running = False
        
        # è¨­å®šä¿¡è™Ÿè™•ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """ä¿¡è™Ÿè™•ç†å™¨"""
        logger.info(f"æ”¶åˆ°ä¿¡è™Ÿ {signum}ï¼Œæ­£åœ¨åœæ­¢ä»»å‹™èª¿åº¦å™¨...")
        asyncio.create_task(self.stop())
    
    async def start(self):
        """å•Ÿå‹•ä»»å‹™èª¿åº¦å™¨"""
        if self.is_running:
            logger.warning("ä»»å‹™èª¿åº¦å™¨å·²åœ¨é‹è¡Œä¸­")
            return
        
        try:
            logger.info("æ­£åœ¨å•Ÿå‹•ä»»å‹™èª¿åº¦å™¨...")
            
            # è¨»å†Šé è¨­ä»»å‹™
            await self._register_default_tasks()
            
            # å•Ÿå‹• WebSocket æ¨é€æœå‹™
            await push_service.start()
            
            # å•Ÿå‹•èª¿åº¦å™¨
            self.scheduler.start()
            self.is_running = True
            
            logger.info(f"ä»»å‹™èª¿åº¦å™¨å·²å•Ÿå‹•ï¼Œè¨»å†Šäº† {len(self.tasks)} å€‹ä»»å‹™")
            
            # è¼¸å‡ºä»»å‹™æ¸…å–®
            for task in self.tasks.values():
                status = "å•Ÿç”¨" if task.enabled else "åœç”¨"
                logger.info(f"  - {task.name} ({task.task_type.value}): {status}")
            
        except Exception as e:
            logger.error(f"å•Ÿå‹•ä»»å‹™èª¿åº¦å™¨å¤±æ•—: {e}")
            raise
    
    async def stop(self):
        """åœæ­¢ä»»å‹™èª¿åº¦å™¨"""
        if not self.is_running:
            return
        
        try:
            logger.info("æ­£åœ¨åœæ­¢ä»»å‹™èª¿åº¦å™¨...")
            
            # åœæ­¢ WebSocket æ¨é€æœå‹™
            await push_service.stop()
            
            # åœæ­¢èª¿åº¦å™¨
            self.scheduler.shutdown(wait=True)
            self.is_running = False
            
            logger.info("ä»»å‹™èª¿åº¦å™¨å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"åœæ­¢ä»»å‹™èª¿åº¦å™¨å¤±æ•—: {e}")
    
    async def _register_default_tasks(self):
        """è¨»å†Šé è¨­ä»»å‹™"""
        
        # ===== æ ¸å¿ƒç›£æ§ä»»å‹™ =====
        
        # 1. ç›£æ§æ•¸æ“šæ”¶é›†ä»»å‹™ï¼ˆæ¯30ç§’åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="monitoring_collection",
            task_type=TaskType.MONITORING_COLLECTION,
            name="ç›£æ§æ•¸æ“šæ”¶é›†",
            description="å®šæ™‚æ”¶é›†æ‰€æœ‰ä¼ºæœå™¨çš„CPUã€è¨˜æ†¶é«”ã€ç£ç¢Ÿã€ç¶²è·¯ç›£æ§æ•¸æ“š",
            trigger="30s",  # æ¯30ç§’
            function=self._execute_monitoring_collection
        )
        
        # 2. WebSocket å³æ™‚æ¨é€ä»»å‹™ï¼ˆæ¯30ç§’åŸ·è¡Œï¼Œç•¥æ™šæ–¼æ•¸æ“šæ”¶é›†ï¼‰
        await self.register_task(
            task_id="websocket_push",
            task_type=TaskType.WEBSOCKET_PUSH,
            name="å³æ™‚æ•¸æ“šæ¨é€",
            description="æ¨é€æœ€æ–°ç›£æ§æ•¸æ“šå’Œç‹€æ…‹è®ŠåŒ–åˆ°æ‰€æœ‰è¨‚é–±çš„å®¢æˆ¶ç«¯",
            trigger="30s",  # æ¯30ç§’
            function=self._execute_websocket_push
        )
        
        # 3. ç³»çµ±è³‡è¨Šæ›´æ–°ä»»å‹™ï¼ˆæ¯5åˆ†é˜åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="system_info_update",
            task_type=TaskType.SYSTEM_INFO_UPDATE,
            name="ç³»çµ±è³‡è¨Šæ›´æ–°",
            description="æ›´æ–°ä¼ºæœå™¨ç³»çµ±è³‡è¨Šï¼ˆç¡¬é«”ã€è»Ÿé«”ã€é‹è¡Œæ™‚é–“ç­‰ï¼‰",
            trigger="*/5 * * * *",  # æ¯5åˆ†é˜
            function=self._execute_system_info_update
        )
        
        # ===== ç¶­è­·ä»»å‹™ =====
        
        # 4. æ•¸æ“šç·©è¡å€åˆ·æ–°ï¼ˆæ¯2åˆ†é˜åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="buffer_flush",
            task_type=TaskType.BUFFER_FLUSH,
            name="ç·©è¡å€åˆ·æ–°",
            description="å¼·åˆ¶åˆ·æ–°æ•¸æ“šè™•ç†ç·©è¡å€",
            trigger="*/2 * * * *",  # æ¯2åˆ†é˜
            function=self._execute_buffer_flush
        )
        
        # 5. ç³»çµ±å¥åº·æª¢æŸ¥ï¼ˆæ¯5åˆ†é˜åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="system_health_check",
            task_type=TaskType.HEALTH_CHECK,
            name="ç³»çµ±å¥åº·æª¢æŸ¥",
            description="æª¢æŸ¥SSHé€£æ¥ã€è³‡æ–™åº«ã€WebSocketç­‰ç³»çµ±çµ„ä»¶ç‹€æ…‹",
            trigger="*/5 * * * *",  # æ¯5åˆ†é˜
            function=self._execute_system_health_check
        )
        
        # 6. å„²å­˜ç©ºé–“ç›£æ§ï¼ˆæ¯30åˆ†é˜åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="storage_monitor",
            task_type=TaskType.STORAGE_MONITOR,
            name="å„²å­˜ç©ºé–“ç›£æ§",
            description="ç›£æ§ç£ç¢Ÿä½¿ç”¨ç‡ä¸¦ç™¼å‡ºè­¦å‘Š",
            trigger="*/30 * * * *",  # æ¯30åˆ†é˜
            function=self._execute_storage_monitor
        )
        
        # 7. æ•¸æ“šæ¸…ç†ä»»å‹™ï¼ˆæ¯å¤©å‡Œæ™¨2é»åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="daily_data_cleanup",
            task_type=TaskType.DATA_CLEANUP,
            name="æ¯æ—¥æ•¸æ“šæ¸…ç†",
            description="è‡ªå‹•æ¸…ç†30å¤©ä»¥ä¸Šçš„èˆŠç›£æ§æ•¸æ“š",
            trigger="0 2 * * *",  # æ¯å¤©å‡Œæ™¨2é»
            function=self._execute_data_cleanup
        )
        
        # 8. æ­¸æª”æ¸…ç†ä»»å‹™ï¼ˆæ¯é€±æ—¥å‡Œæ™¨3é»åŸ·è¡Œï¼‰
        await self.register_task(
            task_id="weekly_archive_cleanup",
            task_type=TaskType.ARCHIVE_CLEANUP,
            name="æ¯é€±æ­¸æª”æ¸…ç†",
            description="è‡ªå‹•æ¸…ç†90å¤©ä»¥ä¸Šçš„æ­¸æª”æª”æ¡ˆ",
            trigger="0 3 * * 0",  # æ¯é€±æ—¥å‡Œæ™¨3é»
            function=self._execute_archive_cleanup
        )
    
    async def register_task(
        self,
        task_id: str,
        task_type: TaskType,
        name: str,
        description: str,
        trigger: str,
        function: Callable,
        enabled: bool = True
    ):
        """è¨»å†Šæ–°ä»»å‹™"""
        try:
            # å‰µå»ºä»»å‹™å®šç¾©
            task = ScheduledTask(
                task_id=task_id,
                task_type=task_type,
                name=name,
                description=description,
                trigger=trigger,
                function=function,
                enabled=enabled
            )
            
            # è§£æè§¸ç™¼å™¨
            if self._is_cron_expression(trigger):
                # Cron è¡¨é”å¼
                trigger_obj = CronTrigger.from_crontab(trigger)
            else:
                # é–“éš”è¡¨é”å¼ï¼ˆå¦‚ "5m", "1h"ï¼‰
                trigger_obj = self._parse_interval_trigger(trigger)
            
            # æ·»åŠ åˆ°èª¿åº¦å™¨
            if enabled:
                job = self.scheduler.add_job(
                    func=self._execute_task_wrapper,
                    trigger=trigger_obj,
                    args=[task_id],
                    id=task_id,
                    name=name,
                    replace_existing=True
                )
                
                # è¨­å®šä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
                task.next_run = job.next_run_time
            
            # ä¿å­˜ä»»å‹™
            self.tasks[task_id] = task
            
            logger.info(f"ä»»å‹™ '{name}' è¨»å†ŠæˆåŠŸ (ID: {task_id})")
            
        except Exception as e:
            logger.error(f"è¨»å†Šä»»å‹™ '{name}' å¤±æ•—: {e}")
            raise
    
    async def _execute_task_wrapper(self, task_id: str, retry_count: int = 0):
        """ä»»å‹™åŸ·è¡ŒåŒ…è£å™¨ï¼ˆå«é‡è©¦æ©Ÿåˆ¶ï¼‰"""
        if task_id not in self.tasks:
            logger.error(f"ä»»å‹™ {task_id} ä¸å­˜åœ¨")
            return
        
        task = self.tasks[task_id]
        
        if not task.enabled:
            logger.info(f"ä»»å‹™ '{task.name}' å·²åœç”¨ï¼Œè·³éåŸ·è¡Œ")
            return
        
        # å‰µå»ºåŸ·è¡Œçµæœè¨˜éŒ„
        execution_result = TaskExecutionResult(
            task_id=task_id,
            task_type=task.task_type,
            status=TaskStatus.RUNNING,
            start_time=datetime.now()
        )
        
        retry_info = f" (é‡è©¦ {retry_count}/{task.max_retries})" if retry_count > 0 else ""
        logger.info(f"é–‹å§‹åŸ·è¡Œä»»å‹™: {task.name}{retry_info}")
        
        try:
            # åŸ·è¡Œä»»å‹™å‡½æ•¸
            result_data = await task.function()
            
            # æ›´æ–°åŸ·è¡Œçµæœ
            execution_result.end_time = datetime.now()
            execution_result.duration = (
                execution_result.end_time - execution_result.start_time
            ).total_seconds()
            execution_result.status = TaskStatus.COMPLETED
            execution_result.result_data = result_data or {}
            
            # ä»»å‹™æˆåŠŸï¼Œé‡ç½®é€£çºŒå¤±æ•—è¨ˆæ•¸å™¨
            task.consecutive_failures = 0
            task.last_run = execution_result.end_time
            task.run_count += 1
            
            logger.info(f"ä»»å‹™ '{task.name}' åŸ·è¡Œå®Œæˆï¼Œè€—æ™‚ {execution_result.duration:.2f}s")
            
        except Exception as e:
            # æ›´æ–°åŸ·è¡Œçµæœ
            execution_result.end_time = datetime.now()
            execution_result.duration = (
                execution_result.end_time - execution_result.start_time
            ).total_seconds()
            execution_result.status = TaskStatus.FAILED
            execution_result.error_message = str(e)
            
            # æ›´æ–°ä»»å‹™çµ±è¨ˆ
            task.failure_count += 1
            task.consecutive_failures += 1
            task.last_failure_time = execution_result.end_time
            
            logger.error(f"ä»»å‹™ '{task.name}' åŸ·è¡Œå¤±æ•—{retry_info}: {e}")
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡è©¦
            should_retry = (
                retry_count < task.max_retries and 
                task.consecutive_failures <= task.auto_disable_threshold and
                task.enabled
            )
            
            if should_retry:
                logger.info(f"ä»»å‹™ '{task.name}' å°‡åœ¨ {task.retry_delay} ç§’å¾Œé‡è©¦")
                
                # å®‰æ’é‡è©¦
                await asyncio.sleep(task.retry_delay)
                return await self._execute_task_wrapper(task_id, retry_count + 1)
            else:
                # æª¢æŸ¥æ˜¯å¦éœ€è¦è‡ªå‹•åœç”¨ä»»å‹™
                if task.consecutive_failures >= task.auto_disable_threshold:
                    logger.critical(
                        f"ä»»å‹™ '{task.name}' é€£çºŒå¤±æ•— {task.consecutive_failures} æ¬¡ï¼Œ"
                        f"é”åˆ°è‡ªå‹•åœç”¨é–¾å€¼ï¼Œå°‡åœç”¨è©²ä»»å‹™"
                    )
                    await self.disable_task(task_id)
                    execution_result.result_data = {
                        "auto_disabled": True,
                        "consecutive_failures": task.consecutive_failures
                    }
        
        finally:
            # è¨˜éŒ„åŸ·è¡Œæ­·å²
            self._add_execution_history(execution_result)
            
            # æ›´æ–°ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
            if task.enabled:
                job = self.scheduler.get_job(task_id)
                if job:
                    task.next_run = job.next_run_time
    
    def _add_execution_history(self, result: TaskExecutionResult):
        """æ·»åŠ åŸ·è¡Œæ­·å²è¨˜éŒ„"""
        self.execution_history.append(result)
        
        # ä¿æŒæ­·å²è¨˜éŒ„æ•¸é‡é™åˆ¶
        if len(self.execution_history) > self.max_history_size:
            self.execution_history = self.execution_history[-self.max_history_size:]
    
    def _is_cron_expression(self, trigger: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚º Cron è¡¨é”å¼"""
        return len(trigger.split()) == 5
    
    def _parse_interval_trigger(self, trigger: str) -> IntervalTrigger:
        """è§£æé–“éš”è§¸ç™¼å™¨"""
        # ç°¡å–®çš„é–“éš”è§£æå™¨ï¼ˆå¦‚ "5m", "1h", "30s"ï¼‰
        if trigger.endswith('s'):
            seconds = int(trigger[:-1])
            return IntervalTrigger(seconds=seconds)
        elif trigger.endswith('m'):
            minutes = int(trigger[:-1])
            return IntervalTrigger(minutes=minutes)
        elif trigger.endswith('h'):
            hours = int(trigger[:-1])
            return IntervalTrigger(hours=hours)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„é–“éš”æ ¼å¼: {trigger}")
    
    # ===== ä»»å‹™åŸ·è¡Œå‡½æ•¸ =====
    
    # ===== æ ¸å¿ƒç›£æ§ä»»å‹™åŸ·è¡Œå‡½æ•¸ =====
    
    async def _execute_monitoring_collection(self) -> Dict[str, Any]:
        """åŸ·è¡Œç›£æ§æ•¸æ“šæ”¶é›†ä»»å‹™"""
        try:
            start_time = time.time()
            
            # ç²å–æ‰€æœ‰æ´»èºçš„ä¼ºæœå™¨
            async for db in get_db():
                servers = db.query(Server).filter(Server.is_active == True).all()
                
                if not servers:
                    logger.info("æ²’æœ‰æ‰¾åˆ°æ´»èºçš„ä¼ºæœå™¨ï¼Œè·³éç›£æ§æ•¸æ“šæ”¶é›†")
                    return {"servers_processed": 0, "success_count": 0}
                
                success_count = 0
                error_count = 0
                total_servers = len(servers)
                
                logger.debug(f"é–‹å§‹æ”¶é›† {total_servers} å°ä¼ºæœå™¨çš„ç›£æ§æ•¸æ“š")
                
                # ä¸¦è¡Œæ”¶é›†æ‰€æœ‰ä¼ºæœå™¨çš„ç›£æ§æ•¸æ“š
                collection_tasks = []
                for server in servers:
                    task = asyncio.create_task(
                        self._collect_server_monitoring_data(server)
                    )
                    collection_tasks.append((server.id, task))
                
                # ç­‰å¾…æ‰€æœ‰æ”¶é›†ä»»å‹™å®Œæˆ
                for server_id, task in collection_tasks:
                    try:
                        await task
                        success_count += 1
                    except Exception as e:
                        error_count += 1
                        logger.error(f"æ”¶é›†ä¼ºæœå™¨ {server_id} ç›£æ§æ•¸æ“šå¤±æ•—: {e}")
                
                elapsed_time = time.time() - start_time
                
                result = {
                    "servers_processed": total_servers,
                    "success_count": success_count,
                    "error_count": error_count,
                    "elapsed_time": elapsed_time,
                    "timestamp": datetime.now().isoformat()
                }
                
                logger.info(
                    f"ç›£æ§æ•¸æ“šæ”¶é›†å®Œæˆ: {success_count}/{total_servers} æˆåŠŸ, "
                    f"è€—æ™‚ {elapsed_time:.2f}s"
                )
                
                return result
                
        except Exception as e:
            logger.error(f"ç›£æ§æ•¸æ“šæ”¶é›†ä»»å‹™å¤±æ•—: {e}")
            raise
    
    async def _collect_server_monitoring_data(self, server: Server):
        """æ”¶é›†å–®ä¸€ä¼ºæœå™¨çš„ç›£æ§æ•¸æ“š"""
        try:
            # æª¢æŸ¥SSHé€£æ¥ç‹€æ…‹
            if not ssh_manager.is_connected(server.id):
                await ssh_manager.connect_to_server(server.id)
            
            # æ”¶é›†ç›£æ§æ•¸æ“š
            metrics_data = await monitoring_service.collect_all_metrics(server.id)
            
            # è™•ç†å’Œå­˜å„²æ•¸æ“š
            if metrics_data:
                await data_processor.process_monitoring_data(server.id, metrics_data)
                logger.debug(f"ä¼ºæœå™¨ {server.id} ç›£æ§æ•¸æ“šæ”¶é›†æˆåŠŸ")
            else:
                logger.warning(f"ä¼ºæœå™¨ {server.id} æœªæ”¶é›†åˆ°ç›£æ§æ•¸æ“š")
                
        except Exception as e:
            logger.error(f"æ”¶é›†ä¼ºæœå™¨ {server.id} ç›£æ§æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    async def _execute_websocket_push(self) -> Dict[str, Any]:
        """åŸ·è¡ŒWebSocketæ¨é€ä»»å‹™"""
        try:
            start_time = time.time()
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é€£æ¥çš„å®¢æˆ¶ç«¯
            if not push_service.has_active_connections():
                return {
                    "active_connections": 0,
                    "pushes_sent": 0,
                    "message": "æ²’æœ‰æ´»èºçš„WebSocketé€£æ¥"
                }
            
            # åŸ·è¡Œæ¨é€æœå‹™çš„å®šæ™‚æ¨é€
            push_result = await push_service.execute_scheduled_push()
            
            elapsed_time = time.time() - start_time
            
            result = {
                "active_connections": push_result.get("active_connections", 0),
                "pushes_sent": push_result.get("pushes_sent", 0),
                "errors": push_result.get("errors", 0),
                "elapsed_time": elapsed_time,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.debug(
                f"WebSocketæ¨é€å®Œæˆ: {result['pushes_sent']} æ¬¡æ¨é€, "
                f"{result['active_connections']} å€‹é€£æ¥, è€—æ™‚ {elapsed_time:.2f}s"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"WebSocketæ¨é€ä»»å‹™å¤±æ•—: {e}")
            raise
    
    async def _execute_system_info_update(self) -> Dict[str, Any]:
        """åŸ·è¡Œç³»çµ±è³‡è¨Šæ›´æ–°ä»»å‹™"""
        try:
            start_time = time.time()
            
            # ç²å–æ‰€æœ‰æ´»èºçš„ä¼ºæœå™¨
            async for db in get_db():
                servers = db.query(Server).filter(Server.is_active == True).all()
                
                if not servers:
                    return {"servers_processed": 0, "success_count": 0}
                
                success_count = 0
                error_count = 0
                
                # ä¸¦è¡Œæ›´æ–°æ‰€æœ‰ä¼ºæœå™¨çš„ç³»çµ±è³‡è¨Š
                for server in servers:
                    try:
                        await system_collector.update_server_system_info(server.id)
                        success_count += 1
                    except Exception as e:
                        error_count += 1
                        logger.error(f"æ›´æ–°ä¼ºæœå™¨ {server.id} ç³»çµ±è³‡è¨Šå¤±æ•—: {e}")
                
                elapsed_time = time.time() - start_time
                
                result = {
                    "servers_processed": len(servers),
                    "success_count": success_count,
                    "error_count": error_count,
                    "elapsed_time": elapsed_time,
                    "timestamp": datetime.now().isoformat()
                }
                
                logger.info(
                    f"ç³»çµ±è³‡è¨Šæ›´æ–°å®Œæˆ: {success_count}/{len(servers)} æˆåŠŸ, "
                    f"è€—æ™‚ {elapsed_time:.2f}s"
                )
                
                return result
                
        except Exception as e:
            logger.error(f"ç³»çµ±è³‡è¨Šæ›´æ–°ä»»å‹™å¤±æ•—: {e}")
            raise
    
    # ===== ç¶­è­·ä»»å‹™åŸ·è¡Œå‡½æ•¸ =====
    
    async def _execute_buffer_flush(self) -> Dict[str, Any]:
        """åŸ·è¡Œç·©è¡å€åˆ·æ–°ä»»å‹™"""
        try:
            stats = await data_processor.flush_all_data()
            return stats.__dict__
        except Exception as e:
            logger.error(f"ç·©è¡å€åˆ·æ–°ä»»å‹™å¤±æ•—: {e}")
            raise
    
    async def _execute_system_health_check(self) -> Dict[str, Any]:
        """åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥ä»»å‹™"""
        try:
            health_data = {
                "timestamp": datetime.now().isoformat(),
                "ssh_connections": {},
                "websocket_status": {},
                "database_status": {},
                "processing_status": {}
            }
            
            # æª¢æŸ¥SSHé€£æ¥ç‹€æ…‹
            async for db in get_db():
                servers = db.query(Server).filter(Server.is_active == True).all()
                ssh_stats = {
                    "total_servers": len(servers),
                    "connected_count": 0,
                    "failed_count": 0,
                    "server_status": {}
                }
                
                for server in servers:
                    is_connected = ssh_manager.is_connected(server.id)
                    ssh_stats["server_status"][server.id] = {
                        "connected": is_connected,
                        "host": server.host
                    }
                    if is_connected:
                        ssh_stats["connected_count"] += 1
                    else:
                        ssh_stats["failed_count"] += 1
                
                health_data["ssh_connections"] = ssh_stats
            
            # æª¢æŸ¥WebSocketç‹€æ…‹
            ws_status = {
                "active_connections": push_service.get_connection_count(),
                "service_running": push_service.is_service_running()
            }
            health_data["websocket_status"] = ws_status
            
            # æª¢æŸ¥æ•¸æ“šè™•ç†ç‹€æ…‹
            processing_stats = data_processor.get_processing_stats()
            health_data["processing_status"] = {
                "total_processed": processing_stats.total_processed,
                "error_count": len(processing_stats.errors),
                "buffer_size": processing_stats.buffer_size
            }
            
            # æª¢æŸ¥å„²å­˜ç©ºé–“
            storage_info = await data_cleaner.get_storage_info()
            health_data["database_status"] = {
                "usage_percentage": storage_info.usage_percentage,
                "database_size_mb": storage_info.database_size_bytes / (1024**2)
            }
            
            # ç™¼å‡ºè­¦å‘Š
            if ssh_stats["failed_count"] > 0:
                logger.warning(f"æœ‰ {ssh_stats['failed_count']} å°ä¼ºæœå™¨SSHé€£æ¥å¤±æ•—")
            
            if not ws_status["service_running"]:
                logger.warning("WebSocketæ¨é€æœå‹™æœªé‹è¡Œ")
            
            if len(processing_stats.errors) > 5:
                logger.warning(f"æ•¸æ“šè™•ç†éŒ¯èª¤éå¤š: {len(processing_stats.errors)} å€‹éŒ¯èª¤")
            
            if storage_info.usage_percentage > 90:
                logger.warning(f"ç£ç¢Ÿä½¿ç”¨ç‡éé«˜: {storage_info.usage_percentage}%")
            
            return health_data
            
        except Exception as e:
            logger.error(f"ç³»çµ±å¥åº·æª¢æŸ¥ä»»å‹™å¤±æ•—: {e}")
            raise
    
    async def _execute_storage_monitor(self) -> Dict[str, Any]:
        """åŸ·è¡Œå„²å­˜ç©ºé–“ç›£æ§ä»»å‹™"""
        try:
            storage_info = await data_cleaner.get_storage_info()
            
            monitor_data = {
                "usage_percentage": storage_info.usage_percentage,
                "free_space_gb": storage_info.free_space_bytes / (1024**3),
                "database_size_mb": storage_info.database_size_bytes / (1024**2),
                "archive_size_mb": storage_info.archive_size_bytes / (1024**2),
                "timestamp": datetime.now().isoformat()
            }
            
            # å„²å­˜ä½¿ç”¨ç‡è­¦å‘Š
            if storage_info.usage_percentage > 95:
                logger.critical(f"ç£ç¢Ÿç©ºé–“åš´é‡ä¸è¶³: {storage_info.usage_percentage}%")
            elif storage_info.usage_percentage > 85:
                logger.warning(f"ç£ç¢Ÿç©ºé–“ä¸è¶³: {storage_info.usage_percentage}%")
            
            return monitor_data
        except Exception as e:
            logger.error(f"å„²å­˜ç›£æ§ä»»å‹™å¤±æ•—: {e}")
            raise
    
    async def _execute_data_cleanup(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ•¸æ“šæ¸…ç†ä»»å‹™"""
        try:
            stats = await data_cleaner.cleanup_old_data(CleanupLevel.BASIC)
            return stats.to_dict()
        except Exception as e:
            logger.error(f"æ•¸æ“šæ¸…ç†ä»»å‹™å¤±æ•—: {e}")
            raise
    
    async def _execute_archive_cleanup(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ­¸æª”æ¸…ç†ä»»å‹™"""
        try:
            stats = await data_cleaner.cleanup_archive_files(90)
            return stats.to_dict()
        except Exception as e:
            logger.error(f"æ­¸æª”æ¸…ç†ä»»å‹™å¤±æ•—: {e}")
            raise
    
    # ===== ç®¡ç†æ–¹æ³• =====
    
    def get_task_list(self) -> List[Dict[str, Any]]:
        """å–å¾—ä»»å‹™æ¸…å–®"""
        return [task.to_dict() for task in self.tasks.values()]
    
    def get_execution_history(
        self, 
        task_id: Optional[str] = None, 
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """å–å¾—åŸ·è¡Œæ­·å²"""
        history = self.execution_history
        
        # æŒ‰ä»»å‹™IDéæ¿¾
        if task_id:
            history = [h for h in history if h.task_id == task_id]
        
        # é™åˆ¶æ•¸é‡ä¸¦æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        history = sorted(history, key=lambda x: x.start_time, reverse=True)[:limit]
        
        return [h.to_dict() for h in history]
    
    async def enable_task(self, task_id: str):
        """å•Ÿç”¨ä»»å‹™"""
        if task_id not in self.tasks:
            raise ValueError(f"ä»»å‹™ {task_id} ä¸å­˜åœ¨")
        
        task = self.tasks[task_id]
        
        if task.enabled:
            logger.info(f"ä»»å‹™ '{task.name}' å·²ç¶“æ˜¯å•Ÿç”¨ç‹€æ…‹")
            return
        
        # å•Ÿç”¨ä»»å‹™
        task.enabled = True
        
        # é‡æ–°æ·»åŠ åˆ°èª¿åº¦å™¨
        if self.is_running:
            trigger_obj = CronTrigger.from_crontab(task.trigger)
            job = self.scheduler.add_job(
                func=self._execute_task_wrapper,
                trigger=trigger_obj,
                args=[task_id],
                id=task_id,
                name=task.name,
                replace_existing=True
            )
            task.next_run = job.next_run_time
        
        logger.info(f"ä»»å‹™ '{task.name}' å·²å•Ÿç”¨")
    
    async def disable_task(self, task_id: str):
        """åœç”¨ä»»å‹™"""
        if task_id not in self.tasks:
            raise ValueError(f"ä»»å‹™ {task_id} ä¸å­˜åœ¨")
        
        task = self.tasks[task_id]
        
        if not task.enabled:
            logger.info(f"ä»»å‹™ '{task.name}' å·²ç¶“æ˜¯åœç”¨ç‹€æ…‹")
            return
        
        # åœç”¨ä»»å‹™
        task.enabled = False
        task.next_run = None
        
        # å¾èª¿åº¦å™¨ç§»é™¤
        if self.is_running:
            try:
                self.scheduler.remove_job(task_id)
            except Exception:
                pass  # ä»»å‹™å¯èƒ½å·²ç¶“ä¸åœ¨èª¿åº¦å™¨ä¸­
        
        logger.info(f"ä»»å‹™ '{task.name}' å·²åœç”¨")
    
    async def run_task_now(self, task_id: str) -> TaskExecutionResult:
        """ç«‹å³åŸ·è¡Œä»»å‹™"""
        if task_id not in self.tasks:
            raise ValueError(f"ä»»å‹™ {task_id} ä¸å­˜åœ¨")
        
        task = self.tasks[task_id]
        
        logger.info(f"æ‰‹å‹•åŸ·è¡Œä»»å‹™: {task.name}")
        
        # ç›´æ¥åŸ·è¡Œä»»å‹™ï¼ˆä¸é€šéèª¿åº¦å™¨ï¼‰
        await self._execute_task_wrapper(task_id)
        
        # è¿”å›æœ€æ–°çš„åŸ·è¡Œçµæœ
        for result in reversed(self.execution_history):
            if result.task_id == task_id:
                return result
        
        raise RuntimeError(f"ä»»å‹™ {task_id} åŸ·è¡Œå¾Œæœªæ‰¾åˆ°çµæœè¨˜éŒ„")
    
    async def reset_task_failures(self, task_id: str):
        """é‡ç½®ä»»å‹™å¤±æ•—è¨ˆæ•¸"""
        if task_id not in self.tasks:
            raise ValueError(f"ä»»å‹™ {task_id} ä¸å­˜åœ¨")
        
        task = self.tasks[task_id]
        task.consecutive_failures = 0
        task.last_failure_time = None
        
        logger.info(f"ä»»å‹™ '{task.name}' å¤±æ•—è¨ˆæ•¸å·²é‡ç½®")
    
    async def update_task_retry_config(
        self, 
        task_id: str, 
        max_retries: Optional[int] = None,
        retry_delay: Optional[float] = None,
        auto_disable_threshold: Optional[int] = None
    ):
        """æ›´æ–°ä»»å‹™é‡è©¦é…ç½®"""
        if task_id not in self.tasks:
            raise ValueError(f"ä»»å‹™ {task_id} ä¸å­˜åœ¨")
        
        task = self.tasks[task_id]
        
        if max_retries is not None:
            task.max_retries = max_retries
        if retry_delay is not None:
            task.retry_delay = retry_delay
        if auto_disable_threshold is not None:
            task.auto_disable_threshold = auto_disable_threshold
        
        logger.info(f"ä»»å‹™ '{task.name}' é‡è©¦é…ç½®å·²æ›´æ–°")
    
    def get_failed_tasks(self) -> List[Dict[str, Any]]:
        """å–å¾—æœ‰å¤±æ•—è¨˜éŒ„çš„ä»»å‹™æ¸…å–®"""
        failed_tasks = []
        for task in self.tasks.values():
            if task.consecutive_failures > 0:
                failed_tasks.append({
                    "task_id": task.task_id,
                    "name": task.name,
                    "consecutive_failures": task.consecutive_failures,
                    "total_failures": task.failure_count,
                    "last_failure_time": task.last_failure_time.isoformat() if task.last_failure_time else None,
                    "enabled": task.enabled,
                    "auto_disable_threshold": task.auto_disable_threshold
                })
        
        return failed_tasks
    
    def get_task_health_summary(self) -> Dict[str, Any]:
        """å–å¾—ä»»å‹™å¥åº·ç‹€æ³æ‘˜è¦"""
        total_tasks = len(self.tasks)
        enabled_tasks = sum(1 for t in self.tasks.values() if t.enabled)
        failed_tasks = sum(1 for t in self.tasks.values() if t.consecutive_failures > 0)
        critical_tasks = sum(1 for t in self.tasks.values() if t.consecutive_failures >= t.auto_disable_threshold)
        
        # è¨ˆç®—æˆåŠŸç‡
        total_runs = sum(t.run_count for t in self.tasks.values())
        total_failures = sum(t.failure_count for t in self.tasks.values())
        success_rate = ((total_runs - total_failures) / total_runs * 100) if total_runs > 0 else 100
        
        return {
            "total_tasks": total_tasks,
            "enabled_tasks": enabled_tasks,
            "disabled_tasks": total_tasks - enabled_tasks,
            "failed_tasks": failed_tasks,
            "critical_tasks": critical_tasks,
            "success_rate": round(success_rate, 2),
            "total_runs": total_runs,
            "total_failures": total_failures,
            "scheduler_running": self.is_running
        }


# å…¨åŸŸä»»å‹™èª¿åº¦å™¨å¯¦ä¾‹
task_scheduler = TaskScheduler()


# ä¾¿åˆ©å‡½æ•¸
async def start_task_scheduler():
    """å•Ÿå‹•ä»»å‹™èª¿åº¦å™¨çš„ä¾¿åˆ©å‡½æ•¸"""
    await task_scheduler.start()


async def stop_task_scheduler():
    """åœæ­¢ä»»å‹™èª¿åº¦å™¨çš„ä¾¿åˆ©å‡½æ•¸"""
    await task_scheduler.stop()


def get_scheduler_status() -> Dict[str, Any]:
    """å–å¾—èª¿åº¦å™¨ç‹€æ…‹çš„ä¾¿åˆ©å‡½æ•¸"""
    return {
        "is_running": task_scheduler.is_running,
        "task_count": len(task_scheduler.tasks),
        "enabled_tasks": sum(1 for t in task_scheduler.tasks.values() if t.enabled),
        "execution_history_size": len(task_scheduler.execution_history)
    }


if __name__ == "__main__":
    # æ¸¬è©¦ä»»å‹™èª¿åº¦å™¨
    
    async def test_scheduler():
        """æ¸¬è©¦èª¿åº¦å™¨"""
        print("ğŸ• æ¸¬è©¦ä»»å‹™èª¿åº¦å™¨...")
        
        try:
            # å•Ÿå‹•èª¿åº¦å™¨
            await task_scheduler.start()
            
            print(f"âœ… èª¿åº¦å™¨å•Ÿå‹•æˆåŠŸ")
            print(f"  - è¨»å†Šä»»å‹™æ•¸: {len(task_scheduler.tasks)}")
            print(f"  - é‹è¡Œç‹€æ…‹: {task_scheduler.is_running}")
            
            # åˆ—å‡ºæ‰€æœ‰ä»»å‹™
            tasks = task_scheduler.get_task_list()
            for task in tasks:
                print(f"  - {task['name']}: {task['trigger']}")
            
            # æ‰‹å‹•åŸ·è¡Œä¸€å€‹ä»»å‹™
            print("\nğŸš€ æ‰‹å‹•åŸ·è¡Œå¥åº·æª¢æŸ¥ä»»å‹™...")
            result = await task_scheduler.run_task_now("hourly_health_check")
            print(f"  - åŸ·è¡Œç‹€æ…‹: {result.status.value}")
            print(f"  - åŸ·è¡Œæ™‚é–“: {result.duration:.2f}s")
            
            # ç­‰å¾…ä¸€æ®µæ™‚é–“å¾Œåœæ­¢
            await asyncio.sleep(2)
            
            # åœæ­¢èª¿åº¦å™¨
            await task_scheduler.stop()
            print(f"âœ… èª¿åº¦å™¨å·²åœæ­¢")
            
        except Exception as e:
            print(f"âŒ èª¿åº¦å™¨æ¸¬è©¦å¤±æ•—: {e}")
    
    # åŸ·è¡Œæ¸¬è©¦
    asyncio.run(test_scheduler())