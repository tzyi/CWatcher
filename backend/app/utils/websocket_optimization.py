"""
CWatcher WebSocket æ€§èƒ½å„ªåŒ–å·¥å…·

æä¾›æ•¸æ“šå£“ç¸®ã€æ‰¹é‡å‚³è¼¸ã€é€£æ¥ç®¡ç†å’Œæ€§èƒ½ç›£æ§åŠŸèƒ½
å„ªåŒ– WebSocket é€šè¨Šæ•ˆç‡å’Œè³‡æºä½¿ç”¨
"""

import asyncio
import json
import gzip
import zlib
import logging
import time
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import uuid

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


class CompressionType(Enum):
    """å£“ç¸®é¡å‹"""
    NONE = "none"
    GZIP = "gzip"
    ZLIB = "zlib"
    JSON_MINIFY = "json_minify"


class MessagePriority(Enum):
    """è¨Šæ¯å„ªå…ˆç´š"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4


@dataclass
class CompressionStats:
    """å£“ç¸®çµ±è¨ˆ"""
    original_size: int
    compressed_size: int
    compression_ratio: float
    compression_time: float
    compression_type: CompressionType
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "original_size": self.original_size,
            "compressed_size": self.compressed_size,
            "compression_ratio": self.compression_ratio,
            "compression_time": self.compression_time,
            "compression_type": self.compression_type.value
        }


@dataclass
class QueuedMessage:
    """ä½‡åˆ—ä¸­çš„è¨Šæ¯"""
    message_id: str
    content: str
    priority: MessagePriority
    target_connections: List[str]
    created_at: datetime = field(default_factory=datetime.now)
    retry_count: int = 0
    max_retries: int = 3
    
    def should_retry(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²é‡è©¦"""
        return self.retry_count < self.max_retries
    
    def increment_retry(self):
        """å¢åŠ é‡è©¦æ¬¡æ•¸"""
        self.retry_count += 1


class MessageCompressor:
    """è¨Šæ¯å£“ç¸®å™¨"""
    
    def __init__(self, default_compression: CompressionType = CompressionType.JSON_MINIFY):
        self.default_compression = default_compression
        self.compression_threshold = 1024  # è¶…é 1KB æ‰å£“ç¸®
        self.stats = {
            "total_messages": 0,
            "compressed_messages": 0,
            "total_original_size": 0,
            "total_compressed_size": 0,
            "compression_time": 0.0
        }
    
    def compress_message(
        self, 
        message: str, 
        compression_type: Optional[CompressionType] = None
    ) -> Tuple[str, CompressionStats]:
        """å£“ç¸®è¨Šæ¯"""
        start_time = time.time()
        
        if compression_type is None:
            compression_type = self.default_compression
        
        original_size = len(message.encode('utf-8'))
        
        # æ±ºå®šæ˜¯å¦éœ€è¦å£“ç¸®
        if original_size < self.compression_threshold and compression_type != CompressionType.JSON_MINIFY:
            compression_type = CompressionType.NONE
        
        try:
            if compression_type == CompressionType.GZIP:
                compressed_data = gzip.compress(message.encode('utf-8'))
                compressed_message = f"GZIP:{len(compressed_data)}:{compressed_data.hex()}"
                
            elif compression_type == CompressionType.ZLIB:
                compressed_data = zlib.compress(message.encode('utf-8'))
                compressed_message = f"ZLIB:{len(compressed_data)}:{compressed_data.hex()}"
                
            elif compression_type == CompressionType.JSON_MINIFY:
                # JSON æœ€å°åŒ–ï¼ˆç§»é™¤ä¸å¿…è¦çš„ç©ºç™½ï¼‰
                try:
                    json_obj = json.loads(message)
                    compressed_message = json.dumps(json_obj, separators=(',', ':'), ensure_ascii=False)
                except json.JSONDecodeError:
                    compressed_message = message
                    
            else:  # CompressionType.NONE
                compressed_message = message
            
            compressed_size = len(compressed_message.encode('utf-8'))
            compression_ratio = compressed_size / original_size if original_size > 0 else 1.0
            compression_time = time.time() - start_time
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats["total_messages"] += 1
            self.stats["total_original_size"] += original_size
            self.stats["total_compressed_size"] += compressed_size
            self.stats["compression_time"] += compression_time
            
            if compression_type != CompressionType.NONE:
                self.stats["compressed_messages"] += 1
            
            stats = CompressionStats(
                original_size=original_size,
                compressed_size=compressed_size,
                compression_ratio=compression_ratio,
                compression_time=compression_time,
                compression_type=compression_type
            )
            
            return compressed_message, stats
            
        except Exception as e:
            logger.error(f"è¨Šæ¯å£“ç¸®å¤±æ•—: {e}")
            # å£“ç¸®å¤±æ•—æ™‚è¿”å›åŸå§‹è¨Šæ¯
            stats = CompressionStats(
                original_size=original_size,
                compressed_size=original_size,
                compression_ratio=1.0,
                compression_time=time.time() - start_time,
                compression_type=CompressionType.NONE
            )
            return message, stats
    
    def decompress_message(self, compressed_message: str) -> str:
        """è§£å£“ç¸®è¨Šæ¯"""
        try:
            if compressed_message.startswith("GZIP:"):
                parts = compressed_message.split(":", 2)
                if len(parts) == 3:
                    size = int(parts[1])
                    hex_data = parts[2]
                    compressed_data = bytes.fromhex(hex_data)
                    return gzip.decompress(compressed_data).decode('utf-8')
                    
            elif compressed_message.startswith("ZLIB:"):
                parts = compressed_message.split(":", 2)
                if len(parts) == 3:
                    size = int(parts[1])
                    hex_data = parts[2]
                    compressed_data = bytes.fromhex(hex_data)
                    return zlib.decompress(compressed_data).decode('utf-8')
            
            # æ²’æœ‰å£“ç¸®æ¨™è¨˜ï¼Œè¿”å›åŸå§‹è¨Šæ¯
            return compressed_message
            
        except Exception as e:
            logger.error(f"è¨Šæ¯è§£å£“ç¸®å¤±æ•—: {e}")
            return compressed_message
    
    def get_compression_stats(self) -> Dict[str, Any]:
        """å–å¾—å£“ç¸®çµ±è¨ˆ"""
        total_saved = self.stats["total_original_size"] - self.stats["total_compressed_size"]
        overall_ratio = (
            self.stats["total_compressed_size"] / self.stats["total_original_size"]
            if self.stats["total_original_size"] > 0 else 1.0
        )
        
        return {
            **self.stats,
            "bytes_saved": total_saved,
            "overall_compression_ratio": overall_ratio,
            "compression_percentage": (1 - overall_ratio) * 100,
            "average_compression_time": (
                self.stats["compression_time"] / self.stats["total_messages"]
                if self.stats["total_messages"] > 0 else 0
            )
        }


class MessageBatcher:
    """è¨Šæ¯æ‰¹é‡è™•ç†å™¨"""
    
    def __init__(self, batch_size: int = 10, batch_timeout: float = 1.0):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.message_queue: List[QueuedMessage] = []
        self.processing_task: Optional[asyncio.Task] = None
        self.is_running = False
        self.stats = {
            "batches_processed": 0,
            "messages_processed": 0,
            "failed_messages": 0,
            "average_batch_size": 0.0,
            "processing_time": 0.0
        }
    
    async def start(self):
        """å•Ÿå‹•æ‰¹é‡è™•ç†"""
        if self.is_running:
            return
        
        self.is_running = True
        self.processing_task = asyncio.create_task(self._batch_processing_loop())
        logger.info("è¨Šæ¯æ‰¹é‡è™•ç†å™¨å·²å•Ÿå‹•")
    
    async def stop(self):
        """åœæ­¢æ‰¹é‡è™•ç†"""
        self.is_running = False
        
        if self.processing_task and not self.processing_task.done():
            self.processing_task.cancel()
            try:
                await self.processing_task
            except asyncio.CancelledError:
                pass
        
        # è™•ç†å‰©é¤˜è¨Šæ¯
        if self.message_queue:
            await self._process_batch(self.message_queue)
            self.message_queue.clear()
        
        logger.info("è¨Šæ¯æ‰¹é‡è™•ç†å™¨å·²åœæ­¢")
    
    def queue_message(self, message: QueuedMessage):
        """å°‡è¨Šæ¯åŠ å…¥ä½‡åˆ—"""
        self.message_queue.append(message)
        
        # æŒ‰å„ªå…ˆç´šæ’åº
        self.message_queue.sort(key=lambda m: m.priority.value, reverse=True)
    
    async def _batch_processing_loop(self):
        """æ‰¹é‡è™•ç†å¾ªç’°"""
        while self.is_running:
            try:
                if len(self.message_queue) >= self.batch_size:
                    # é”åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³è™•ç†
                    batch = self.message_queue[:self.batch_size]
                    self.message_queue = self.message_queue[self.batch_size:]
                    await self._process_batch(batch)
                    
                elif self.message_queue:
                    # ç­‰å¾…è¶…æ™‚å¾Œè™•ç†
                    await asyncio.sleep(self.batch_timeout)
                    if self.message_queue:
                        batch = self.message_queue.copy()
                        self.message_queue.clear()
                        await self._process_batch(batch)
                else:
                    # ä½‡åˆ—ç‚ºç©ºï¼Œç­‰å¾…ä¸€æ®µæ™‚é–“
                    await asyncio.sleep(0.1)
                    
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ‰¹é‡è™•ç†å¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(1)
    
    async def _process_batch(self, batch: List[QueuedMessage]):
        """è™•ç†ä¸€æ‰¹è¨Šæ¯"""
        if not batch:
            return
        
        start_time = time.time()
        
        try:
            # æŒ‰ç›®æ¨™é€£æ¥åˆ†çµ„
            connection_groups: Dict[str, List[QueuedMessage]] = {}
            
            for message in batch:
                for connection_id in message.target_connections:
                    if connection_id not in connection_groups:
                        connection_groups[connection_id] = []
                    connection_groups[connection_id].append(message)
            
            # ä¸¦è¡Œè™•ç†å„å€‹é€£æ¥
            tasks = [
                self._send_to_connection(connection_id, messages)
                for connection_id, messages in connection_groups.items()
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # çµ±è¨ˆçµæœ
            successful_messages = 0
            failed_messages = 0
            
            for result in results:
                if isinstance(result, Exception):
                    failed_messages += 1
                else:
                    successful_messages += result
            
            # æ›´æ–°çµ±è¨ˆ
            self.stats["batches_processed"] += 1
            self.stats["messages_processed"] += successful_messages
            self.stats["failed_messages"] += failed_messages
            self.stats["processing_time"] += time.time() - start_time
            
            if self.stats["batches_processed"] > 0:
                self.stats["average_batch_size"] = (
                    self.stats["messages_processed"] / self.stats["batches_processed"]
                )
            
            logger.debug(f"æ‰¹é‡è™•ç†å®Œæˆ: {len(batch)} è¨Šæ¯, {successful_messages} æˆåŠŸ, {failed_messages} å¤±æ•—")
            
        except Exception as e:
            logger.error(f"æ‰¹é‡è™•ç†å¤±æ•—: {e}")
    
    async def _send_to_connection(self, connection_id: str, messages: List[QueuedMessage]) -> int:
        """ç™¼é€è¨Šæ¯åˆ°ç‰¹å®šé€£æ¥"""
        successful_count = 0
        
        try:
            # é€™è£¡æ‡‰è©²å¯¦éš›ç™¼é€åˆ° WebSocket é€£æ¥
            # æš«æ™‚æ¨¡æ“¬ç™¼é€æˆåŠŸ
            await asyncio.sleep(0.01)  # æ¨¡æ“¬ç¶²è·¯å»¶é²
            successful_count = len(messages)
            
        except Exception as e:
            logger.error(f"ç™¼é€åˆ°é€£æ¥ {connection_id} å¤±æ•—: {e}")
            
            # è™•ç†é‡è©¦
            for message in messages:
                if message.should_retry():
                    message.increment_retry()
                    self.queue_message(message)
        
        return successful_count
    
    def get_batch_stats(self) -> Dict[str, Any]:
        """å–å¾—æ‰¹é‡è™•ç†çµ±è¨ˆ"""
        return {
            **self.stats,
            "queue_size": len(self.message_queue),
            "is_running": self.is_running,
            "batch_size": self.batch_size,
            "batch_timeout": self.batch_timeout
        }


class ConnectionLimiter:
    """é€£æ¥æ•¸é‡é™åˆ¶å™¨"""
    
    def __init__(self, max_connections: int = 1000, max_connections_per_ip: int = 10):
        self.max_connections = max_connections
        self.max_connections_per_ip = max_connections_per_ip
        self.connections: Dict[str, str] = {}  # connection_id -> client_ip
        self.ip_connections: Dict[str, Set[str]] = {}  # client_ip -> connection_ids
        self.connection_lock = asyncio.Lock()
    
    async def can_accept_connection(self, client_ip: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥æ¥å—æ–°é€£æ¥"""
        async with self.connection_lock:
            # æª¢æŸ¥ç¸½é€£æ¥æ•¸
            if len(self.connections) >= self.max_connections:
                return False
            
            # æª¢æŸ¥å–®å€‹ IP çš„é€£æ¥æ•¸
            ip_connection_count = len(self.ip_connections.get(client_ip, set()))
            if ip_connection_count >= self.max_connections_per_ip:
                return False
            
            return True
    
    async def add_connection(self, connection_id: str, client_ip: str):
        """æ·»åŠ é€£æ¥"""
        async with self.connection_lock:
            self.connections[connection_id] = client_ip
            
            if client_ip not in self.ip_connections:
                self.ip_connections[client_ip] = set()
            self.ip_connections[client_ip].add(connection_id)
    
    async def remove_connection(self, connection_id: str):
        """ç§»é™¤é€£æ¥"""
        async with self.connection_lock:
            if connection_id not in self.connections:
                return
            
            client_ip = self.connections[connection_id]
            del self.connections[connection_id]
            
            if client_ip in self.ip_connections:
                self.ip_connections[client_ip].discard(connection_id)
                
                # å¦‚æœè©² IP æ²’æœ‰å…¶ä»–é€£æ¥ï¼Œç§»é™¤è¨˜éŒ„
                if not self.ip_connections[client_ip]:
                    del self.ip_connections[client_ip]
    
    def get_connection_stats(self) -> Dict[str, Any]:
        """å–å¾—é€£æ¥çµ±è¨ˆ"""
        return {
            "total_connections": len(self.connections),
            "max_connections": self.max_connections,
            "max_connections_per_ip": self.max_connections_per_ip,
            "unique_ips": len(self.ip_connections),
            "ip_distribution": {
                ip: len(connections) 
                for ip, connections in self.ip_connections.items()
            }
        }


class WebSocketOptimizer:
    """WebSocket å„ªåŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        self.compressor = MessageCompressor()
        self.batcher = MessageBatcher()
        self.connection_limiter = ConnectionLimiter()
        self.is_running = False
    
    async def start(self):
        """å•Ÿå‹•å„ªåŒ–å™¨"""
        if self.is_running:
            return
        
        self.is_running = True
        await self.batcher.start()
        logger.info("WebSocket å„ªåŒ–å™¨å·²å•Ÿå‹•")
    
    async def stop(self):
        """åœæ­¢å„ªåŒ–å™¨"""
        if not self.is_running:
            return
        
        self.is_running = False
        await self.batcher.stop()
        logger.info("WebSocket å„ªåŒ–å™¨å·²åœæ­¢")
    
    async def optimize_and_send_message(
        self,
        message: str,
        target_connections: List[str],
        priority: MessagePriority = MessagePriority.NORMAL,
        compression_type: Optional[CompressionType] = None
    ) -> bool:
        """å„ªåŒ–ä¸¦ç™¼é€è¨Šæ¯"""
        try:
            # å£“ç¸®è¨Šæ¯
            compressed_message, compression_stats = self.compressor.compress_message(
                message, compression_type
            )
            
            # å»ºç«‹ä½‡åˆ—è¨Šæ¯
            queued_message = QueuedMessage(
                message_id=str(uuid.uuid4()),
                content=compressed_message,
                priority=priority,
                target_connections=target_connections
            )
            
            # åŠ å…¥æ‰¹é‡è™•ç†ä½‡åˆ—
            self.batcher.queue_message(queued_message)
            
            return True
            
        except Exception as e:
            logger.error(f"å„ªåŒ–ä¸¦ç™¼é€è¨Šæ¯å¤±æ•—: {e}")
            return False
    
    async def can_accept_connection(self, client_ip: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦å¯ä»¥æ¥å—æ–°é€£æ¥"""
        return await self.connection_limiter.can_accept_connection(client_ip)
    
    async def register_connection(self, connection_id: str, client_ip: str):
        """è¨»å†Šæ–°é€£æ¥"""
        await self.connection_limiter.add_connection(connection_id, client_ip)
    
    async def unregister_connection(self, connection_id: str):
        """è¨»éŠ·é€£æ¥"""
        await self.connection_limiter.remove_connection(connection_id)
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """å–å¾—å„ªåŒ–çµ±è¨ˆ"""
        return {
            "compression_stats": self.compressor.get_compression_stats(),
            "batch_stats": self.batcher.get_batch_stats(),
            "connection_stats": self.connection_limiter.get_connection_stats(),
            "is_running": self.is_running
        }


# å…¨åŸŸå„ªåŒ–å™¨å¯¦ä¾‹
websocket_optimizer = WebSocketOptimizer()


# ä¾¿åˆ©å‡½æ•¸
async def start_websocket_optimizer():
    """å•Ÿå‹• WebSocket å„ªåŒ–å™¨"""
    await websocket_optimizer.start()


async def stop_websocket_optimizer():
    """åœæ­¢ WebSocket å„ªåŒ–å™¨"""
    await websocket_optimizer.stop()


async def send_optimized_message(
    message: str,
    target_connections: List[str],
    priority: MessagePriority = MessagePriority.NORMAL,
    compression_type: Optional[CompressionType] = None
) -> bool:
    """ç™¼é€å„ªåŒ–éçš„è¨Šæ¯"""
    return await websocket_optimizer.optimize_and_send_message(
        message, target_connections, priority, compression_type
    )


if __name__ == "__main__":
    # æ¸¬è©¦å„ªåŒ–å·¥å…·
    
    async def test_compression():
        """æ¸¬è©¦å£“ç¸®åŠŸèƒ½"""
        print("ğŸ“¦ æ¸¬è©¦è¨Šæ¯å£“ç¸®...")
        
        compressor = MessageCompressor()
        
        # æ¸¬è©¦æ•¸æ“š
        test_message = json.dumps({
            "type": "monitoring_update",
            "data": {
                "server_id": 1,
                "cpu": {"usage": 45.2, "cores": 4},
                "memory": {"usage": 68.5, "total": 8192},
                "disk": {"usage": 76.3, "total": 500000},
                "network": {"download": 2.4, "upload": 0.8}
            }
        }, indent=2)
        
        print(f"åŸå§‹å¤§å°: {len(test_message)} bytes")
        
        # æ¸¬è©¦ä¸åŒå£“ç¸®æ–¹å¼
        for compression_type in CompressionType:
            compressed, stats = compressor.compress_message(test_message, compression_type)
            print(f"{compression_type.value}: {stats.compressed_size} bytes "
                  f"({stats.compression_ratio:.2%})")
        
        print(f"âœ… å£“ç¸®çµ±è¨ˆ: {compressor.get_compression_stats()}")
    
    async def test_batcher():
        """æ¸¬è©¦æ‰¹é‡è™•ç†"""
        print("\nğŸ“¨ æ¸¬è©¦æ‰¹é‡è™•ç†...")
        
        batcher = MessageBatcher(batch_size=3, batch_timeout=0.5)
        await batcher.start()
        
        # æ·»åŠ æ¸¬è©¦è¨Šæ¯
        for i in range(5):
            message = QueuedMessage(
                message_id=f"msg_{i}",
                content=f"Test message {i}",
                priority=MessagePriority.NORMAL,
                target_connections=[f"conn_{i % 2}"]
            )
            batcher.queue_message(message)
        
        # ç­‰å¾…è™•ç†
        await asyncio.sleep(2)
        
        print(f"âœ… æ‰¹é‡çµ±è¨ˆ: {batcher.get_batch_stats()}")
        
        await batcher.stop()
    
    async def test_optimizer():
        """æ¸¬è©¦å®Œæ•´å„ªåŒ–å™¨"""
        print("\nğŸš€ æ¸¬è©¦ WebSocket å„ªåŒ–å™¨...")
        
        optimizer = WebSocketOptimizer()
        await optimizer.start()
        
        # æ¸¬è©¦é€£æ¥é™åˆ¶
        can_connect = await optimizer.can_accept_connection("127.0.0.1")
        print(f"å¯ä»¥å»ºç«‹é€£æ¥: {can_connect}")
        
        # è¨»å†Šé€£æ¥
        await optimizer.register_connection("conn_1", "127.0.0.1")
        
        # ç™¼é€å„ªåŒ–è¨Šæ¯
        test_data = {"type": "test", "data": {"value": 123}}
        success = await optimizer.send_optimized_message(
            json.dumps(test_data),
            ["conn_1"],
            MessagePriority.HIGH
        )
        print(f"è¨Šæ¯ç™¼é€æˆåŠŸ: {success}")
        
        # ç­‰å¾…è™•ç†
        await asyncio.sleep(1)
        
        # å–å¾—çµ±è¨ˆ
        stats = optimizer.get_optimization_stats()
        print(f"âœ… å„ªåŒ–çµ±è¨ˆ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
        await optimizer.stop()
    
    async def test_complete():
        """å®Œæ•´æ¸¬è©¦"""
        print("=" * 50)
        print("ğŸ§ª WebSocket æ€§èƒ½å„ªåŒ–å·¥å…·æ¸¬è©¦")
        print("=" * 50)
        
        await test_compression()
        await test_batcher()
        await test_optimizer()
        
        print("\nâœ… æ€§èƒ½å„ªåŒ–å·¥å…·æ¸¬è©¦å®Œæˆ")
    
    # åŸ·è¡Œæ¸¬è©¦
    import asyncio
    asyncio.run(test_complete())